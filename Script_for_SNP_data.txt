#Trace DNA from kill sites identifies predating tigers#
#Authors: Himanshu Chhattani, Abishek Harihar, Rounak Dean, Ajay Yadav, Kaushal Patel, Divyashree Rana, Awadhesh Pandit, Sanjay Kumar Shukla, Vincent Rahim, Uma Ramakrishnan
#Script adopted from Natesh et al, 2019 and Sagar et al, 2021.

#Make a separate directory for each analysis run, and within this directory create subdirectories for raw data, trimmed files, bam files etc#
##Move into this directory and define path to the analysis directory
DATA_PATH='/home/NGS_data'

#copy all the raw fastq files in $DATA_PATH}/rawData

#Making subdirectories within this directory
mkdir trimmedFiles ##trimmed files to be stored here##
mkdir bamFiles ##bamFiles to be stored here##
mkdir vcfFiltering ##vcf file to be created and filtered here##

#STEP 1: Trimming fastq files

for file in ${DATA_PATH}/rawData/*_L001_R1_001.fastq.gz #assumes that fastq files have extension '_L001_R1_001.fastq.gz' and '_L001_R2_001.fastq.gz'
do
base=$(basename ${file} _L001_R1_001.fastq.gz)
trim_galore --quality 30 --phred33 --fastqc --illumina --stringency 5 --length 5 --output_dir ${DATA_PATH}/trimmedFiles --paired ${DATA_PATH}/rawData/${base}_L001_R1_001.fastq.gz ${DATA_PATH}/rawData/${base}_L001_R2_001.fastq.gz
done

#STEP 2: Mapping reads to genomes, generating bam files

for file in ${DATA_PATH}/trimmedFiles/*_L001_R1_001_val_1.fq.gz #assumes that trimmed fastq files have extension '_L001_R1_001_val_1.fq.gz' and '_L001_R2_001_val_2.fq.gz'
do
base=$(basename ${file} _L001_R1_001_val_1.fq.gz)
readGroupString=@RG\\tID:${base}\\tSM:${base}\\tLB:${base}\\tPL:illumina
bwa-0.7.17/bwa mem -M -R ${readGroupString} -t 30 -B 3 referenceGenome.fa ${DATA_PATH}/trimmedFiles/${base}_L001_R1_001_val_1.fq.gz ${DATA_PATH}/trimmedFiles/${base}_L001_R2_001_val_2.fq.gz | samtools view -hu - | samtools sort -O bam - > ${DATA_PATH}/bamFiles/${base}_bwa_mem.bam
samtools index ${DATA_PATH}/bamFiles/${base}_bwa_mem.bam
done

#STEP 3: Creating VCF
#first need to create list of bam files
cd ~/
ls ${DATA_PATH}/bamFiles/*.bam > ${DATA_PATH}/bamFiles/listBams
cd ${DATA_PATH}/
mkdir ${DATA_PATH}/temp #create a temporary directory for bcftools to store temperary files#
#now beginning the variant calling at specific postions (SNP panel)#
bcftools-1.6/bcftools mpileup -Ou --max-depth 10000 -f referenceGenome.fa --bam-list ${DATA_PATH}/bamFiles/listBams -R SNP-positions-file --annotate FORMAT/AD,FORMAT/DP,INFO/AD | bcftools-1.6/bcftools call -Ou -c -f GQ | bcftools-1.6/bcftools sort --temp-dir ${DATA_PATH}/temp -Oz -o ${DATA_PATH}/vcfFiltering/vcfFile_forIndID.vcf.gz



# NOW FILTERING VCF ##

#This script includes steps of filtering the mpcr data VCF before individual identification is done using pi-hat relatedness values.

#Remove indels and uncompress the vcf - requires vcftools
vcftools --gzvcf vcfFile_forIndID.vcf.gz --remove-indels --out vcfFile_forIndID_noIndel --recode #assumes the input file name as vcfFile_forIndID

#Filtering out genotypes based on genotype quality and depth
vcftools --vcf vcfFile_forIndID_noIndel.recode.vcf --minDP 10 --minGQ 10 --out vcfFile_forIndID_noIndel_GQ10_DP10 --recode


#Calculate missing data  per site - requires vcftools
vcftools --vcf vcfFile_forIndID_noIndel_GQ10_DP10.vcf --missing-site --out vcfFile_forIndID_noIndel_GQ10_DP10

#following this, loci with missing data for more than 10% individuals and minor allele count 1 were filtered out - requires vcftools
vcftools --vcf vcfFile_forIndID_noIndel_GQ10_DP10.vcf --max-missing 0.1 --mac 1 --out vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1 --recode

#caldulate missing data per sample - requires vcftools
vcftools --vcf vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1.recode.vcf --missing-indv --out vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1

#Filtered out samples with genotypes called at less than 50 sites (out of remaining 102) - requires vcftools
awk '$4>55' vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1.imiss | cut -f1 > indWithMissingDataOn55sites.txt #from 95 sites, samples with genotypes called at minimum 40 sites were kept
vcftools --vcf vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1.recode.vcf --remove indWithMissingDataOn52sites.txt --out vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1_ind40snps --recode

#Estimating pi-hat relatedness - requires plink
plink-1.9/plink --vcf vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1_ind40snps.recode.vcf --genome --aec --const-fid --out vcfFile_forIndID_noIndel_GQ10_DP10_mac1_maxMiss0.1_ind40snps

